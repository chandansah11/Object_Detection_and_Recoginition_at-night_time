{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "annotations_path = r'C:\\Users\\Admin\\Desktop\\CapstoneProject\\capstone\\ExDark\\ExDark\\annotationsCSVfile.csv'\n",
    "annotations = pd.read_csv(annotations_path)\n",
    "\n",
    "dataset_path = r'C:\\Users\\Admin\\Desktop\\CapstoneProject\\capstone\\ExDark\\AnotedImages'\n",
    "annotations['image_path'] = annotations['image_path'].apply(lambda x: os.path.join(dataset_path, x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_paths = annotations['image_path'].tolist()\n",
    "bounding_boxes = annotations[['x_tl', 'y_tl', 'x_br', 'y_br']].values.tolist()\n",
    "class_labels = annotations['class'].tolist()\n",
    "\n",
    "image_paths_train, image_paths_val, bounding_boxes_train, bounding_boxes_val, class_labels_train, class_labels_val = train_test_split(\n",
    "    image_paths, bounding_boxes, class_labels, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, bbox, class_label):\n",
    "    img = image.load_img(image_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array /= 255.0\n",
    "\n",
    "    # Normalize bounding box coordinates to the range [0, 1]\n",
    "    bbox = [\n",
    "        bbox[0] / img_array.shape[1],\n",
    "        bbox[1] / img_array.shape[0],\n",
    "        bbox[2] / img_array.shape[1],\n",
    "        bbox[3] / img_array.shape[0]\n",
    "    ]\n",
    "\n",
    "    return img_array, {'boxes': [bbox], 'labels': [class_label]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet_backbone(input_shape=(224, 224, 3)):\n",
    "    base_model = keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    backbone = keras.Model(inputs=base_model.input, outputs=base_model.get_layer('conv4_block6_out').output, name='resnet_backbone')\n",
    "    return backbone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rpn(input_tensor, num_anchors=9):\n",
    "    x = layers.Conv2D(512, (3, 3), padding='same', activation='relu', kernel_initializer='normal', name='rpn_conv')(input_tensor)\n",
    "    rpn_cls = layers.Conv2D(num_anchors * 2, (1, 1), activation='linear', name='rpn_cls')(x)\n",
    "    rpn_reg = layers.Conv2D(num_anchors * 4, (1, 1), activation='linear', name='rpn_reg')(x)\n",
    "\n",
    "    model = keras.Model(inputs=input_tensor, outputs=[rpn_cls, rpn_reg], name='rpn_model')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier(base_model, num_classes, input_shape):\n",
    "    x = layers.GlobalAveragePooling2D()(base_model.output)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "\n",
    "    # Calculate the total size of the flattened feature vector\n",
    "    flattened_size = int(np.prod(input_shape[1:]))  # Exclude the batch size dimension\n",
    "    \n",
    "    x = layers.Dense(flattened_size, activation='softmax', name='cls_output')(x)\n",
    "\n",
    "    # Reshape x to match the specified input_shape\n",
    "    x = layers.Reshape((input_shape[1], input_shape[2], -1))(x)\n",
    "\n",
    "    model = keras.Model(inputs=base_model.input, outputs=x, name='classifier_model')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_faster_rcnn(input_shape=(224, 224, 3), num_anchors=9):\n",
    "    # ResNet Backbone\n",
    "    resnet_backbone = build_resnet_backbone(input_shape)\n",
    "    rpn_input = resnet_backbone.output\n",
    "\n",
    "    # RPN Model\n",
    "    rpn_model = build_rpn(rpn_input, num_anchors)\n",
    "    rpn_cls_output, _ = rpn_model(rpn_input)\n",
    "\n",
    "    # Classifier Input\n",
    "    classifier_input = layers.Input(shape=(7, 7, num_anchors * 4), name='classifier_input')\n",
    "\n",
    "    # Build classifier model with correct input shape\n",
    "    classifier_model = build_classifier(base_model=resnet_backbone, num_classes=num_classes, input_shape=(7, 7, num_anchors * 4))\n",
    "\n",
    "    # Pass rpn_cls_output directly to classifier_model\n",
    "    roi_features = classifier_model(rpn_cls_output)\n",
    "\n",
    "    # Faster RCNN Model\n",
    "    faster_rcnn_model = keras.Model(\n",
    "        inputs=resnet_backbone.input,\n",
    "        outputs=[rpn_model(rpn_input), roi_features],\n",
    "        name='faster_rcnn_model'\n",
    "    )\n",
    "\n",
    "    return faster_rcnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"classifier_model\" (type Functional).\n\nInput 0 of layer \"conv1_conv\" is incompatible with the layer: expected axis -1 of input shape to have value 3, but received input with shape (None, 20, 20, 18)\n\nCall arguments received by layer \"classifier_model\" (type Functional):\n  • inputs=tf.Tensor(shape=(None, 14, 14, 18), dtype=float32)\n  • training=None\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[83], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m11\u001b[39m\n\u001b[0;32m      2\u001b[0m num_anchors \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m9\u001b[39m\n\u001b[1;32m----> 4\u001b[0m faster_rcnn \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_faster_rcnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m faster_rcnn\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrpn_model\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier_model\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m      6\u001b[0m faster_rcnn\u001b[38;5;241m.\u001b[39msummary()\n",
      "Cell \u001b[1;32mIn[82], line 17\u001b[0m, in \u001b[0;36mbuild_faster_rcnn\u001b[1;34m(input_shape, num_anchors)\u001b[0m\n\u001b[0;32m     14\u001b[0m classifier_model \u001b[38;5;241m=\u001b[39m build_classifier(base_model\u001b[38;5;241m=\u001b[39mresnet_backbone, num_classes\u001b[38;5;241m=\u001b[39mnum_classes, input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m7\u001b[39m, num_anchors \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m4\u001b[39m))\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Pass rpn_cls_output directly to classifier_model\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m roi_features \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrpn_cls_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Faster RCNN Model\u001b[39;00m\n\u001b[0;32m     20\u001b[0m faster_rcnn_model \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mModel(\n\u001b[0;32m     21\u001b[0m     inputs\u001b[38;5;241m=\u001b[39mresnet_backbone\u001b[38;5;241m.\u001b[39minput,\n\u001b[0;32m     22\u001b[0m     outputs\u001b[38;5;241m=\u001b[39m[rpn_model(rpn_input), roi_features],\n\u001b[0;32m     23\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfaster_rcnn_model\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     24\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\input_spec.py:280\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    275\u001b[0m             value \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mvalue\n\u001b[0;32m    276\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape_as_list[\u001b[38;5;28mint\u001b[39m(axis)] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[0;32m    277\u001b[0m             value,\n\u001b[0;32m    278\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    279\u001b[0m         }:\n\u001b[1;32m--> 280\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    281\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    282\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    283\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    284\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut received input with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    285\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdisplay_shape(x\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    286\u001b[0m             )\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape\u001b[38;5;241m.\u001b[39mrank \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"classifier_model\" (type Functional).\n\nInput 0 of layer \"conv1_conv\" is incompatible with the layer: expected axis -1 of input shape to have value 3, but received input with shape (None, 20, 20, 18)\n\nCall arguments received by layer \"classifier_model\" (type Functional):\n  • inputs=tf.Tensor(shape=(None, 14, 14, 18), dtype=float32)\n  • training=None\n  • mask=None"
     ]
    }
   ],
   "source": [
    "num_classes = 11\n",
    "num_anchors = 9\n",
    "\n",
    "faster_rcnn = build_faster_rcnn()\n",
    "faster_rcnn.compile(optimizer='adam', loss={'rpn_model': 'binary_crossentropy', 'classifier_model': 'categorical_crossentropy'})\n",
    "faster_rcnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train_dataset = tf.data.Dataset.from_tensor_slices((image_paths_train, bounding_boxes_train, class_labels_train))\n",
    "# train_dataset = train_dataset.map(preprocess_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
